{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Outcome oriented prediction with CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.utils as torch_utils\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader,Dataset\n",
    "from torchvision import transforms\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Jul 27 17:26:18 2020       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 396.51                 Driver Version: 396.51                    |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  GeForce GTX 108...  Off  | 00000000:02:00.0  On |                  N/A |\n",
      "| 25%   38C    P8    16W / 250W |   2505MiB / 11177MiB |     27%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  GeForce GTX 108...  Off  | 00000000:03:00.0 Off |                  N/A |\n",
      "| 23%   35C    P8    16W / 250W |     12MiB / 11178MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  GeForce GTX 108...  Off  | 00000000:82:00.0 Off |                  N/A |\n",
      "| 23%   36C    P8    17W / 250W |     12MiB / 11178MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  GeForce GTX 108...  Off  | 00000000:83:00.0 Off |                  N/A |\n",
      "| 23%   34C    P8    16W / 250W |     12MiB / 11178MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                       GPU Memory |\n",
      "|  GPU       PID   Type   Process name                             Usage      |\n",
      "|=============================================================================|\n",
      "|    0      4340      C   python3                                      161MiB |\n",
      "|    0      5258      C   /opt/anaconda3/bin/python3                   159MiB |\n",
      "|    0     13663      G   compiz                                       150MiB |\n",
      "|    0     16724      C   /opt/anaconda3/bin/python3                   155MiB |\n",
      "|    0     16727      C   /opt/anaconda3/bin/python3                   155MiB |\n",
      "|    0     16728      C   /opt/anaconda3/bin/python3                   155MiB |\n",
      "|    0     16731      C   /opt/anaconda3/bin/python3                   155MiB |\n",
      "|    0     16761      C   /opt/anaconda3/bin/python3                   155MiB |\n",
      "|    0     16765      C   /opt/anaconda3/bin/python3                   155MiB |\n",
      "|    0     16766      C   /opt/anaconda3/bin/python3                   155MiB |\n",
      "|    0     16780      C   /opt/anaconda3/bin/python3                   155MiB |\n",
      "|    0     16805      C   /opt/anaconda3/bin/python3                   155MiB |\n",
      "|    0     16821      C   /opt/anaconda3/bin/python3                   155MiB |\n",
      "|    0     16947      G   /usr/lib/xorg/Xorg                           140MiB |\n",
      "|    0     20956      C   python3                                      161MiB |\n",
      "|    0     31689      C   /opt/anaconda3/bin/python3                   163MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct custom dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Customdataset(Dataset):\n",
    "    def __init__(self,x_data,y_data,transform=None):\n",
    "        '''\n",
    "        Call stored dataset\n",
    "        \n",
    "        Params\n",
    "        second: Ellapsed second from the beginning of events \n",
    "        encoding_type: Encoding method for outcomeprediction ex) Static, last_state, aggregation, etc.\n",
    "        '''\n",
    "        \n",
    "        \n",
    "        \n",
    "        # Transforms\n",
    "        self.transform = transform\n",
    "        self.y_data=y_data.to_numpy()\n",
    "        self.x_data=x_data.to_numpy()\n",
    "    def __len__(self):\n",
    "        return len(self.x_data)\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        \n",
    "        # Convert x and y data to torch flaot tensor\n",
    "        x = torch.FloatTensor(self.x_data[idx])\n",
    "        y = self.y_data[idx]\n",
    "        return x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding_type = 'last_state'\n",
    "prefix = 5\n",
    "input_data = pd.read_csv('../data/'+encoding_type+'_'+str(prefix)+'.csv')\n",
    "y_data = input_data.loc[:,['Label']]\n",
    "input_data = input_data.drop(['Label'],axis=1)\n",
    "x_data = input_data\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_data, y_data, test_size=0.33, random_state=69)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = Customdataset(x_train,y_train)\n",
    "testset = Customdataset(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size =5\n",
    "train_loader = DataLoader(trainset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(testset,batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self, input_size,hidden_size, num_layers, output_size,batch_size):\n",
    "        super(CNN,self).__init__()\n",
    "        \n",
    "        self.input_size =  input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.num_layers = num_layers\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "        # GRU part\n",
    "        self.gru = nn.GRU(6000,hidden_size,num_layers,batch_first=True,dropout=0.2)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "\n",
    "        # CNN part\n",
    "        self.cnn1 = nn.Sequential(\n",
    "            nn.Conv1d(input_size,6000,2,padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(2),\n",
    "            nn.Dropout(p=0.2)\n",
    "        )\n",
    "\n",
    "        self.cnn2 = nn.Sequential(\n",
    "            nn.Conv1d(6000,6000,2,padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(2),\n",
    "            nn.Dropout(p=0.2)\n",
    "        )\n",
    "\n",
    "        # Linear        \n",
    "        self.fcs =nn.Sequential(\n",
    "            nn.Dropout(p=0.2),\n",
    "            nn.Linear(hidden_size,500),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.2),\n",
    "            nn.Linear(500, 250),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.2),\n",
    "            nn.Linear(250, output_size),\n",
    "        )\n",
    "        \n",
    "        \n",
    "        \n",
    "    def forward(self,inputs,hidden):        \n",
    "        hidden = hidden.reshape(self.num_layers,batch_size,-1)        \n",
    "        inputs = inputs.reshape(batch_size,-1,timepoint)\n",
    "        output = self.cnn1(inputs)\n",
    "        output = self.cnn2(output)\n",
    "        output = output.reshape([batch_size,-1,output.shape[1]])\n",
    "        \n",
    "        output,hidden = self.gru(output,hidden)\n",
    "        output = self.relu(output)\n",
    "        output = self.fcs(output)\n",
    "        output = output[:,-1]\n",
    " \n",
    "        return output,hidden\n",
    "    \n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1,batch_size,self.hidden_size)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
