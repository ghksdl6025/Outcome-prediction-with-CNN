{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Outcome oriented prediction with CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.utils as torch_utils\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader,Dataset\n",
    "from torchvision import transforms\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "# !nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct custom dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Customdataset(Dataset):\n",
    "    def __init__(self,x_data,y_data,transform=None):\n",
    "        '''\n",
    "        Call stored dataset\n",
    "        \n",
    "        Params\n",
    "        second: Ellapsed second from the beginning of events \n",
    "        encoding_type: Encoding method for outcomeprediction ex) Static, last_state, aggregation, etc.\n",
    "        '''\n",
    "        \n",
    "            \n",
    "        # Transforms\n",
    "        self.y_data=np.array(y_data)\n",
    "        self.x_data=x_data\n",
    "    def __len__(self):\n",
    "        return len(self.x_data)\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        \n",
    "        # Convert x and y data to torch flaot tensor\n",
    "        x = self.x_data[idx]\n",
    "        y = self.y_data[idx]\n",
    "        return x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding_type = 'indexbase'\n",
    "prefix = 5\n",
    "input_data = pd.read_csv('../data/bpic2011/'+encoding_type+'_prefix'+str(prefix)+'.csv')\n",
    "input_data =input_data.drop(['Case ID'],axis=1)\n",
    "\n",
    "y_data = [int(y) for y in list(input_data['Label'])]\n",
    "input_data = input_data.drop(['Label'],axis=1)\n",
    "\n",
    "x_data = input_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_cat =['Activity','Section','Specialism code','Producer code','org:group','Timemonth','Timeweekday','Timehour']\n",
    "event_con =['Duration','Cumduration']\n",
    "event_cat_col=[]\n",
    "event_con_col=[]\n",
    "\n",
    "for col in x_data.columns.values:\n",
    "    for e_col in event_cat:\n",
    "        if e_col in col:\n",
    "            event_cat_col.append(col)\n",
    "    for e_col in event_con:\n",
    "        if e_col in col:\n",
    "            event_con_col.append(col)\n",
    "        \n",
    "only_event_cat = x_data.loc[:,event_cat_col]\n",
    "vocab = {word: i+2 for i, word in enumerate(event_cat_col)}\n",
    "vocab['<boc>'] =0\n",
    "vocab['<eoc>'] =1\n",
    "\n",
    "embedding_layer = nn.Embedding(num_embeddings = len(vocab), \n",
    "                               embedding_dim = 6,\n",
    "                               padding_idx = 1)\n",
    "\n",
    "event_cat_col = sorted(event_cat_col,key=lambda x:x.split('_')[1])\n",
    "event_con_col = sorted(event_con_col,key=lambda x:x.split('_')[1])\n",
    "\n",
    "nx_data = []\n",
    "for row in range(len(x_data)):\n",
    "    row_train=[]\n",
    "    count=1\n",
    "    pre_prefix=0\n",
    "    for pos,col in enumerate(event_cat_col):\n",
    "        if x_data.loc[row,col] ==1:\n",
    "            row_train.append(vocab[col])\n",
    "            if pre_prefix != col.split('_')[1]:\n",
    "                pre_prefix=col.split('_')[1]\n",
    "                count =1\n",
    "            else:\n",
    "                count +=1\n",
    "    for pos,col in enumerate(event_con_col):\n",
    "        row_train.append(x_data.loc[row,col])\n",
    "    row_train = torch.tensor(row_train, dtype=torch.float)\n",
    "    nx_data.append(row_train)\n",
    "    \n",
    "x_train, x_test, y_train, y_test = train_test_split(nx_data, y_data, test_size=0.33, random_state=69)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train[:-1]\n",
    "y_train = y_train[:-1]\n",
    "x_test = x_test[:-1]\n",
    "y_test = y_test[:-1]\n",
    "\n",
    "trainset = Customdataset(x_train,y_train)\n",
    "testset = Customdataset(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size =10\n",
    "train_loader = DataLoader(trainset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(testset,batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data description\n",
    "Train case :630\n",
    "Test case: 310\n",
    "\n",
    "\n",
    "So,  \n",
    "Event log: BPIC 2011  \n",
    "prefix length: 5  \n",
    "Number of event categorical attributes: 8  \n",
    "Number of event categorical attributes columns in pre-preprocessed: 839\n",
    "Number of event continuous attributes: 2  \n",
    "Number of items in single event (including embedding_dim_size,5): 10 (42,âˆµ 8\\*5+2)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN_prediction(nn.Module):\n",
    "    def __init__(self,vocab_size, embedding_dim,batch_size):\n",
    "        super(CNN_prediction,self).__init__()\n",
    "        \n",
    "        # CNN part       \n",
    "        self.embeddings = nn.Embedding(len(vocab), embedding_dim)\n",
    "\n",
    "        self.relu = nn.LeakyReLU()\n",
    "        self.subsampling = nn.MaxPool1d(2,2)\n",
    "        self.dropout = nn.Dropout(p=0.1)\n",
    "        self.c1 = nn.Conv1d(in_channels=5, out_channels=30, kernel_size=10, stride=50)\n",
    "                \n",
    "#         self.linear1 = nn.Linear(15,15)\n",
    "        self.linear2 = nn.Linear(15,1)\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "\n",
    "        \"\"\"\n",
    "        implement code here\n",
    "        \"\"\"\n",
    "        \n",
    "        l3=[]\n",
    "        for case in inputs:\n",
    "            con = case[-10:]\n",
    "            cat = case[:-10].long()\n",
    "            \n",
    "            l1 = self.embeddings(cat).view(5,-1)\n",
    "            rearrange=[]\n",
    "            for pos,k in enumerate(l1):  \n",
    "                t = torch.cat((k,con[pos*2:pos*2+2]))\n",
    "                rearrange.append(t)\n",
    "            l2 = torch.cat(rearrange).view(5,-1)\n",
    "            l3.append(l2)\n",
    "            \n",
    "        hidden = torch.cat(l3)\n",
    "        hidden = hidden.view(batch_size,5,-1)\n",
    "        hidden = self.c1(hidden)\n",
    "        hidden = hidden.permute(0,2,1)\n",
    "        hidden = self.relu(hidden)\n",
    "        hidden = self.subsampling(hidden)\n",
    "        hidden = hidden.view(batch_size,-1)\n",
    "\n",
    "        hidden = self.dropout(hidden)\n",
    "#         hidden = self.linear1(hidden)\n",
    "        hidden = self.relu(hidden)\n",
    "\n",
    "        hidden = self.linear2(hidden)\n",
    "\n",
    "        outputs = hidden.squeeze(1)\n",
    "        return outputs\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Hyperparameters\n",
    "\"\"\"\n",
    "you can change the value\n",
    "\"\"\"\n",
    "num_epochs = 100\n",
    "batch_size = 10\n",
    "embedding_dim=6\n",
    "\n",
    "# Model\n",
    "model = CNN_prediction(len(vocab),embedding_dim = embedding_dim,batch_size=batch_size).cuda()\n",
    "\n",
    "# Loss function & Optimizers\n",
    "\"\"\"\n",
    "you can change the loss and optimizer\n",
    "\"\"\"\n",
    "criterion = torch.nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0005, weight_decay=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_acc(train_predict, train_y):\n",
    "    train_predict_tag = torch.round(torch.sigmoid(train_predict))\n",
    "    correct_results_sum = (train_predict_tag == train_y).sum().float()\n",
    "    acc = correct_results_sum/train_y.shape[0]\n",
    "    acc = torch.round(acc *100)\n",
    "    \n",
    "    return acc    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "train accuracy: 49.21 %, test accuracy: 60.65 %\n",
      "epoch:1, train_loss: 0.7083, test_loss: 0.6719\n",
      "Saving model\n",
      "\n",
      "train accuracy: 70.32 %, test accuracy: 69.68 %\n",
      "epoch:6, train_loss: 0.5685, test_loss: 0.5985\n",
      "Saving model\n",
      "\n",
      "train accuracy: 74.13 %, test accuracy: 68.39 %\n",
      "epoch:11, train_loss: 0.5321, test_loss: 0.5868\n",
      "Saving model\n",
      "\n",
      "train accuracy: 76.51 %, test accuracy: 63.55 %\n",
      "epoch:16, train_loss: 0.4977, test_loss: 0.6077\n",
      "\n",
      "train accuracy: 79.21 %, test accuracy: 64.84 %\n",
      "epoch:21, train_loss: 0.4765, test_loss: 0.6221\n",
      "\n",
      "train accuracy: 80.63 %, test accuracy: 63.87 %\n",
      "epoch:26, train_loss: 0.4338, test_loss: 0.6443\n",
      "\n",
      "train accuracy: 83.33 %, test accuracy: 64.84 %\n",
      "epoch:31, train_loss: 0.4073, test_loss: 0.6406\n",
      "\n",
      "train accuracy: 85.56 %, test accuracy: 64.52 %\n",
      "epoch:36, train_loss: 0.3773, test_loss: 0.6868\n",
      "\n",
      "train accuracy: 85.08 %, test accuracy: 62.26 %\n",
      "epoch:41, train_loss: 0.3542, test_loss: 0.6954\n",
      "\n",
      "train accuracy: 87.62 %, test accuracy: 64.52 %\n",
      "epoch:46, train_loss: 0.3175, test_loss: 0.7133\n",
      "\n",
      "train accuracy: 88.25 %, test accuracy: 64.84 %\n",
      "epoch:51, train_loss: 0.3004, test_loss: 0.7245\n",
      "\n",
      "train accuracy: 88.89 %, test accuracy: 62.90 %\n",
      "epoch:56, train_loss: 0.2739, test_loss: 0.7804\n",
      "\n",
      "train accuracy: 90.63 %, test accuracy: 62.90 %\n",
      "epoch:61, train_loss: 0.2601, test_loss: 0.8004\n",
      "\n",
      "train accuracy: 91.43 %, test accuracy: 61.61 %\n",
      "epoch:66, train_loss: 0.2266, test_loss: 0.8603\n",
      "\n",
      "train accuracy: 92.86 %, test accuracy: 62.26 %\n",
      "epoch:71, train_loss: 0.2090, test_loss: 0.8593\n",
      "\n",
      "train accuracy: 92.86 %, test accuracy: 62.58 %\n",
      "epoch:76, train_loss: 0.1988, test_loss: 0.8908\n",
      "\n",
      "train accuracy: 94.13 %, test accuracy: 62.26 %\n",
      "epoch:81, train_loss: 0.1821, test_loss: 0.9163\n",
      "\n",
      "train accuracy: 94.44 %, test accuracy: 64.52 %\n",
      "epoch:86, train_loss: 0.1752, test_loss: 0.9252\n",
      "\n",
      "train accuracy: 95.87 %, test accuracy: 61.29 %\n",
      "epoch:91, train_loss: 0.1579, test_loss: 0.9930\n",
      "\n",
      "train accuracy: 95.87 %, test accuracy: 61.94 %\n",
      "epoch:96, train_loss: 0.1445, test_loss: 1.0180\n"
     ]
    }
   ],
   "source": [
    "# Train CNN_prediction first\n",
    "accuracy_graph = {'train':[], 'test':[], 'epoch': []}\n",
    "loss_graph = {'train':[], 'test':[], 'epoch': []}\n",
    "best_loss=10\n",
    "for epoch in range(num_epochs):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    # Training\n",
    "    for train_x, train_y in train_loader: \n",
    "        train_x,train_y = train_x.cuda(), train_y.cuda()\n",
    "        train_predict = model(train_x)\n",
    "        train_predict = train_predict.float()\n",
    "        train_y = train_y.float()\n",
    "        loss = criterion(train_predict, train_y)\n",
    "        \n",
    "        acc = binary_acc(train_predict, train_y)\n",
    "\n",
    "        # Backpropagation        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "\n",
    "    # Evaluation\n",
    "    if epoch % 5 ==0:\n",
    "        \n",
    "        test_acc = 0\n",
    "        test_loss =0\n",
    "        \n",
    "        for test_x, test_y in test_loader:\n",
    "\n",
    "            with torch.autograd.no_grad():\n",
    "                test_x, test_y = test_x.cuda(), test_y.cuda()\n",
    "                test_predict = model(test_x)\n",
    "            test_predict = test_predict.float()\n",
    "            test_y = test_y.float()\n",
    "\n",
    "            loss = criterion(test_predict, test_y)\n",
    "            acc = binary_acc(test_predict, test_y)\n",
    "            \n",
    "            test_loss += loss.item()\n",
    "            test_acc += acc.item()\n",
    "                               \n",
    "        print(\"\\ntrain accuracy: {:.2f} %, test accuracy: {:.2f} %\".format(epoch_acc/len(train_loader), test_acc/len(test_loader)))\n",
    "        print(\"epoch:{}, train_loss: {:.4f}, test_loss: {:.4f}\".format(epoch+1, epoch_loss/len(train_loader), test_loss/len(test_loader))) \n",
    "        accuracy_graph['epoch'] = epoch+1\n",
    "        accuracy_graph['train'] = epoch_acc/len(train_loader)\n",
    "\n",
    "        loss_graph['epoch'].append(epoch+1)\n",
    "        loss_graph['train'].append(epoch_loss/len(train_loader))\n",
    "        loss_graph['test'].append(test_loss/len(test_loader))\n",
    "    \n",
    "        if test_loss/len(test_loader) < best_loss:\n",
    "            best_loss = test_loss/len(test_loader)\n",
    "            print('Saving model')\n",
    "            torch.save(model.state_dict(), \"./cnn_pred.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.58      0.62       153\n",
      "           1       0.64      0.73      0.68       157\n",
      "\n",
      "    accuracy                           0.65       310\n",
      "   macro avg       0.66      0.65      0.65       310\n",
      "weighted avg       0.66      0.65      0.65       310\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_acc = 0\n",
    "test_loss =0\n",
    "y_predict_list=[]\n",
    "device = torch.device(\"cuda\")\n",
    "model = CNN_prediction(len(vocab),embedding_dim = embedding_dim,batch_size=batch_size).cuda()\n",
    "model.load_state_dict(torch.load(\"./cnn_pred.pt\", map_location=\"cuda:0\"))\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "testset = Customdataset(x_test,y_test)\n",
    "test_loader = DataLoader(testset,batch_size=10)\n",
    "\n",
    "with torch.autograd.no_grad():\n",
    "    for test_x, test_y in test_loader:\n",
    "        \n",
    "        test_x, test_y = test_x.cuda(), test_y.cuda()\n",
    "        test_predict = model(test_x)\n",
    "        test_predict = test_predict.float()\n",
    "        test_y = test_y.float()\n",
    "        \n",
    "        test_predict_tag = torch.round(torch.sigmoid(test_predict))\n",
    "        y_predict_list.append(test_predict_tag.cpu().numpy())\n",
    "\n",
    "y_predict=[]\n",
    "for y in y_predict_list:\n",
    "    for t in y:\n",
    "        y_predict.append(t)\n",
    "\n",
    "print(classification_report(y_test,y_predict))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
