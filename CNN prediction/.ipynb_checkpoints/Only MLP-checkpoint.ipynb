{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.utils as torch_utils\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader,Dataset\n",
    "from torchvision import transforms\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Aug  5 17:53:23 2020       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 396.51                 Driver Version: 396.51                    |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  GeForce GTX 108...  Off  | 00000000:02:00.0 Off |                  N/A |\n",
      "| 31%   54C    P2    59W / 250W |   5778MiB / 11177MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  GeForce GTX 108...  Off  | 00000000:03:00.0 Off |                  N/A |\n",
      "| 23%   36C    P8    16W / 250W |     12MiB / 11178MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  GeForce GTX 108...  Off  | 00000000:82:00.0 Off |                  N/A |\n",
      "| 23%   37C    P8    17W / 250W |     12MiB / 11178MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  GeForce GTX 108...  Off  | 00000000:83:00.0 Off |                  N/A |\n",
      "| 23%   35C    P8    16W / 250W |     12MiB / 11178MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                       GPU Memory |\n",
      "|  GPU       PID   Type   Process name                             Usage      |\n",
      "|=============================================================================|\n",
      "|    0      4118      C   python3                                      159MiB |\n",
      "|    0      5258      C   /opt/anaconda3/bin/python3                   159MiB |\n",
      "|    0      6419      C   /opt/anaconda3/bin/python3                   161MiB |\n",
      "|    0      6420      C   /opt/anaconda3/bin/python3                   161MiB |\n",
      "|    0      6437      C   /opt/anaconda3/bin/python3                   161MiB |\n",
      "|    0      6438      C   /opt/anaconda3/bin/python3                   161MiB |\n",
      "|    0      6440      C   /opt/anaconda3/bin/python3                   161MiB |\n",
      "|    0      6441      C   /opt/anaconda3/bin/python3                   161MiB |\n",
      "|    0      6442      C   /opt/anaconda3/bin/python3                   161MiB |\n",
      "|    0      6443      C   /opt/anaconda3/bin/python3                   161MiB |\n",
      "|    0      6444      C   /opt/anaconda3/bin/python3                   161MiB |\n",
      "|    0      6448      C   /opt/anaconda3/bin/python3                   161MiB |\n",
      "|    0     12117      C   python3                                      161MiB |\n",
      "|    0     16724      C   /opt/anaconda3/bin/python3                   155MiB |\n",
      "|    0     16727      C   /opt/anaconda3/bin/python3                   155MiB |\n",
      "|    0     16728      C   /opt/anaconda3/bin/python3                   155MiB |\n",
      "|    0     16731      C   /opt/anaconda3/bin/python3                   155MiB |\n",
      "|    0     16761      C   /opt/anaconda3/bin/python3                   155MiB |\n",
      "|    0     16765      C   /opt/anaconda3/bin/python3                   155MiB |\n",
      "|    0     16766      C   /opt/anaconda3/bin/python3                   155MiB |\n",
      "|    0     16780      C   /opt/anaconda3/bin/python3                   155MiB |\n",
      "|    0     16805      C   /opt/anaconda3/bin/python3                   155MiB |\n",
      "|    0     16821      C   /opt/anaconda3/bin/python3                   155MiB |\n",
      "|    0     16947      G   /usr/lib/xorg/Xorg                            47MiB |\n",
      "|    0     20253      C   python3                                      155MiB |\n",
      "|    0     31468      C   /opt/anaconda3/bin/python3                   161MiB |\n",
      "|    0     31469      C   /opt/anaconda3/bin/python3                   161MiB |\n",
      "|    0     31471      C   /opt/anaconda3/bin/python3                   161MiB |\n",
      "|    0     31472      C   /opt/anaconda3/bin/python3                   161MiB |\n",
      "|    0     31473      C   /opt/anaconda3/bin/python3                   161MiB |\n",
      "|    0     31474      C   /opt/anaconda3/bin/python3                   161MiB |\n",
      "|    0     31475      C   /opt/anaconda3/bin/python3                   161MiB |\n",
      "|    0     31476      C   /opt/anaconda3/bin/python3                   161MiB |\n",
      "|    0     31493      C   /opt/anaconda3/bin/python3                   161MiB |\n",
      "|    0     31495      C   /opt/anaconda3/bin/python3                   161MiB |\n",
      "|    0     31689      C   /opt/anaconda3/bin/python3                   163MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct custom dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Customdataset(Dataset):\n",
    "    def __init__(self,x_data,y_data,transform=None):\n",
    "        '''\n",
    "        Call stored dataset\n",
    "        \n",
    "        Params\n",
    "        second: Ellapsed second from the beginning of events \n",
    "        encoding_type: Encoding method for outcomeprediction ex) Static, last_state, aggregation, etc.\n",
    "        '''\n",
    "        \n",
    "        \n",
    "        \n",
    "        # Transforms\n",
    "        self.transform = transform\n",
    "        self.y_data=y_data.to_numpy()\n",
    "        self.x_data=x_data.to_numpy()\n",
    "    def __len__(self):\n",
    "        return len(self.x_data)\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        \n",
    "        # Convert x and y data to torch flaot tensor\n",
    "        x = torch.FloatTensor(self.x_data[idx])\n",
    "        y = self.y_data[idx]\n",
    "        return x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding_type = 'last_state'\n",
    "prefix = 5\n",
    "input_data = pd.read_csv('../data/'+encoding_type+'_'+str(prefix)+'.csv')\n",
    "y_data = input_data.loc[:,['Label']]\n",
    "input_data = input_data.drop(['Label'],axis=1)\n",
    "x_data = input_data\n",
    "x_data = x_data.drop('(case) SUMleges',axis=1)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_data, y_data, test_size=0.33, random_state=69)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = Customdataset(x_train,y_train)\n",
    "testset = Customdataset(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size =10\n",
    "train_loader = DataLoader(trainset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(testset,batch_size=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data description\n",
    "X value  \n",
    "BPIC 2015_2 train loader dataset size is 1 \\* 816  \n",
    "Each rows is a case and 5 cases for one train iteration due to batch_size is 1.  \n",
    "817 elements are included in a single case which are timestamp related information, case and event attributes.  \n",
    "\n",
    "Y value  \n",
    "Size of y value is 1 and content is 0 or 1 binary class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP_prediction(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MLP_prediction,self).__init__()\n",
    "        \n",
    "        # MLP part\n",
    "        self.batchnorm1 = nn.BatchNorm1d(1632)\n",
    "        self.batchnorm2 = nn.BatchNorm1d(1632)\n",
    "        self.layer_1 = nn.Linear(816,1632)\n",
    "        self.layer_2 = nn.Linear(1632,1632)\n",
    "        self.layer_3 = nn.Linear(816,1)\n",
    "        self.dropout = nn.Dropout(p=0.1)\n",
    "        self.relu = nn.Sigmoid()\n",
    "        \n",
    "    \n",
    "    def forward(self, inputs):\n",
    "\n",
    "        \"\"\"\n",
    "        implement code here\n",
    "        \"\"\"\n",
    "        \n",
    "        hidden = self.relu(self.layer_1(inputs))\n",
    "\n",
    "#         hidden = self.batchnorm1(hidden)\n",
    "        hidden = self.relu(self.layer_2(hidden))\n",
    "#         hidden = self.batchnorm2(hidden)\n",
    "        hidden = self.dropout(hidden)\n",
    "        hidden = self.layer_3(hidden)\n",
    "        outputs = hidden.squeeze(1)\n",
    "        return outputs\n",
    "\n",
    "model = MLP_prediction().cuda()\n",
    "\n",
    "# Loss function & Optimizers\n",
    "\"\"\"\n",
    "you can change the loss and optimizer\n",
    "\"\"\"\n",
    "criterion = torch.nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)#, weight_decay=1e-4)\n",
    "\n",
    "\n",
    "\n",
    "# Hyperparameters\n",
    "\"\"\"\n",
    "you can change the value\n",
    "\"\"\"\n",
    "num_epochs = 100\n",
    "batch_size = 10   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_acc(train_predict, train_y):\n",
    "    train_predict_tag = torch.round(torch.sigmoid(train_predict))\n",
    "    correct_results_sum = (train_predict_tag == train_y).sum().float()\n",
    "    acc = correct_results_sum/train_y.shape[0]\n",
    "    acc = torch.round(acc *100)\n",
    "    \n",
    "    return acc    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "train accuracy: 69.29 %, test accuracy: 71.90 %\n",
      "epoch:1, train_loss: 0.6619, test_loss: 0.6616\n",
      "\n",
      "train accuracy: 71.61 %, test accuracy: 74.09 %\n",
      "epoch:11, train_loss: 0.6633, test_loss: 0.6616\n",
      "\n",
      "train accuracy: 73.04 %, test accuracy: 73.36 %\n",
      "epoch:21, train_loss: 0.6614, test_loss: 0.6602\n",
      "\n",
      "train accuracy: 75.18 %, test accuracy: 72.63 %\n",
      "epoch:31, train_loss: 0.6586, test_loss: 0.6615\n",
      "\n",
      "train accuracy: 71.96 %, test accuracy: 71.90 %\n",
      "epoch:41, train_loss: 0.6630, test_loss: 0.6616\n",
      "\n",
      "train accuracy: 70.36 %, test accuracy: 74.09 %\n",
      "epoch:51, train_loss: 0.6660, test_loss: 0.6597\n",
      "\n",
      "train accuracy: 72.50 %, test accuracy: 72.26 %\n",
      "epoch:61, train_loss: 0.6621, test_loss: 0.6626\n",
      "\n",
      "train accuracy: 71.07 %, test accuracy: 73.72 %\n",
      "epoch:71, train_loss: 0.6644, test_loss: 0.6615\n",
      "\n",
      "train accuracy: 71.43 %, test accuracy: 71.53 %\n",
      "epoch:81, train_loss: 0.6650, test_loss: 0.6645\n",
      "\n",
      "train accuracy: 71.07 %, test accuracy: 74.45 %\n",
      "epoch:91, train_loss: 0.6631, test_loss: 0.6603\n"
     ]
    }
   ],
   "source": [
    "# Train CNN_prediction first\n",
    "\n",
    "accuracy_graph = {'train':[], 'test':[], 'epoch': []}\n",
    "loss_graph = {'train':[], 'test':[], 'epoch': []}\n",
    "model = MLP_prediction().cuda()\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    # Training\n",
    "    for train_x, train_y in train_loader: \n",
    "        train_y = train_y.squeeze(1)\n",
    "        train_x, train_y = train_x.cuda(), train_y.cuda()\n",
    "        \n",
    "        \n",
    "        train_predict = model(train_x)\n",
    "        train_predict = train_predict.float()\n",
    "        train_y = train_y.float()\n",
    "        \n",
    "        loss = criterion(torch.sigmoid(train_predict), train_y)\n",
    "        acc = binary_acc(train_predict, train_y)\n",
    "\n",
    "        # Backpropagation        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "                \n",
    "\n",
    "    # Evaluation\n",
    "    if epoch % 10 ==0:\n",
    "        \n",
    "        test_acc = 0\n",
    "        test_loss =0\n",
    "        \n",
    "        for test_x, test_y in test_loader:\n",
    "\n",
    "            with torch.autograd.no_grad():\n",
    "                test_y = test_y.squeeze(1)\n",
    "                test_x, test_y = test_x.cuda(), test_y.cuda()\n",
    "                test_predict = model(test_x)\n",
    "            test_predict = test_predict.float()\n",
    "            test_y = test_y.float()\n",
    "\n",
    "            loss = criterion(torch.sigmoid(test_predict), test_y)\n",
    "            acc = binary_acc(test_predict, test_y)\n",
    "            \n",
    "            test_loss += loss.item()\n",
    "            test_acc += acc.item()\n",
    "                               \n",
    "        print(\"\\ntrain accuracy: {:.2f} %, test accuracy: {:.2f} %\".format(epoch_acc/len(train_loader), test_acc/len(test_loader)))\n",
    "        print(\"epoch:{}, train_loss: {:.4f}, test_loss: {:.4f}\".format(epoch+1, epoch_loss/len(train_loader), test_loss/len(test_loader))) \n",
    "        accuracy_graph['epoch'] = epoch+1\n",
    "        accuracy_graph['train'] = epoch_acc/len(train_loader)\n",
    "\n",
    "        loss_graph['epoch'] = epoch+1\n",
    "        loss_graph['train'] = epoch_loss/len(train_loader)\n",
    "        loss_graph['test'] = test_loss/len(test_loader)\n",
    "\n",
    "\n",
    "#         torch.save(model.state_dict(), \"./cnn_predic.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.82      1.00      0.90       224\n",
      "         1.0       0.00      0.00      0.00        50\n",
      "\n",
      "    accuracy                           0.82       274\n",
      "   macro avg       0.41      0.50      0.45       274\n",
      "weighted avg       0.67      0.82      0.74       274\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/suhwan/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "test_acc = 0\n",
    "test_loss =0\n",
    "y_predict_list=[]\n",
    "model.eval()\n",
    "\n",
    "testset = Customdataset(x_test,y_test)\n",
    "test_loader = DataLoader(testset,batch_size=1)\n",
    "\n",
    "with torch.autograd.no_grad():\n",
    "    for test_x, test_y in test_loader:\n",
    "        test_y = test_y.squeeze(1)\n",
    "        test_x, test_y = test_x.cuda(), test_y.cuda()\n",
    "        test_predict = model(test_x)\n",
    "\n",
    "        test_predict = test_predict.float()\n",
    "        test_y = test_y.float()\n",
    "        \n",
    "        test_predict_tag = torch.round(torch.sigmoid(test_predict))\n",
    "        y_predict_list.append(test_predict_tag.cpu().numpy())\n",
    "        \n",
    "print(classification_report(y_test,y_predict_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
